Obesity, a serious chronic disease, is on the rise as a result of how easily food can be brought to our door steps. People's need for food grew, and at the same time, their anxiety about their nutrition also grew. This study offers an image-based calorie estimation system that asks the user to upload an image of a food item in order to calculate the estimated number of calories in the image. It is a multitasking system that displays weekly information on a user's calorie consumption and the number of calories that must be ingested to prevent obesity-related illnesses like cancer, heart attack, etc. To recognize complex pictures, a collection of food images with 20 classes and 500 images are built in each class. This study has developed a six-layer Convolutional Neural Network (CNN) architecture for the purpose of extracting the traits and classifying the images. The proposed food identification trials had an accuracy of 78.7% during testing and 93.29% throughout training.   By using software designed to accurately estimate food calories from still images, users and healthcare experts may be able to more rapidly detect dietary practices and food choices connected to health and health concerns. Calorie calculation has been done by using photographs, however, it is difficult, and there is presently nopublicly available program that can conduct both food estimation using images and provide health information about the individual.

Convolutional layer learnable filters are trained to respond to certain features in the input data. We were able to categories 520 distinct food and drink products across a wide variety of food categories using this architecture with an accuracy of 86.72% on a recognition dataset of 225,953 512 512-pixel images and On a detection dataset of 130,517 pictures, 94.47% were detected. On a collection of photos that were both self-acquired and taken, we also conducted a real-world test by people with Parkinson's disease using a smartphone camera. According to the findings, the top-five accuracy for realworld photos was 55%.

Using Google, the sample in this block was manually downloaded from Kaggle, and some of the train and test pictures included noise, had different color intensities, and had images with the wrong tags. For storage and suitable train and test phases, we additionally downscaled the images to 50x50 pixels. It becomes clear how tough it is to categories foods because of all the many types that may be found in the actual world. Given the size and variety of the collection, it will be difficult to identify all the different cultures in the sample. The better choice, in many eyes, is to utilize neural networks. The potential of neural networks to absorb patterns that aren't immediately linear-separable is the main reason behind Option 9's success in overcoming scaling issues. It is able to deal with additional environmental factors including noise pictures and much 
more. 

The image-net database may be accessed and utilized by many people. A dataset that may be utilized for picture categorization has undergone extensive CNN training. It now contains a large number of classification categories In order to generalize the system model, the Kaggle dataset was manually downloaded via Google to the CNN model. The model's attributes also include the following: Max Pooling downscale is used to downsize the input photos to 50x50 in each spatial dimension. 0.4 dropout rate with the SoftMax activation function. 

![image](https://github.com/user-attachments/assets/63923699-dc20-4f68-a6b2-27a87491014d)

The size, shape, colour, and texture of the food are used in this way to identify it. Based on the input, a system is developed that can recognise food. The technology also helps in calculating how many calories are in the dish. The stages of image processing that produce the competent model, which, utilising the training dataset, can categorise any image, include pre-processing and neural network training. It uses the 90483 photos of 131 fruits and vegetables from the Fruits 360 collection. In our project, we take into account 15 different kinds of produce. The photos are scaled from their original 100x100 proportions to 224*224. When photos are resized, they are transformed into 4D tensors with the shape (1, 224, 224, 3), which may subsequently be fed into a CNN for learning. 

To make the depiction of a photograph more understandable and easier to analyse, segmentation is a technique that divides a computer-generated image into a number of segments. An edge detection approach is used to reduce a grayscale picture to just black and white pixels. The numbers between 1 and 254 indicate different tones of grey. A graphic value of 0 typically symbolises white, whereas a value of 255 often represents black. By counting the contours and identifying the greatest contour, a division dependent on contours is accomplished. To convert the photograph the fruit pixels are extracted after using HSV to exclude the plate and plate-related pixels from the picture. After that, we set the two fundamental morphological processes of erosion and dilation into action. Erosion was employed to remove pixels from edges and corners before refraction was applied to add units to the item. The meal's location was then established. After that, we see a picture of the fruit by itself (in this case apple). To acquire the food area, a number of morphological processes must be conducted for various foods several times. To compute area, pixels are converted to square centimetres. To do this, we divide the area by the surface area of the skin and multiply the result by a certain amount. 

Convolution neural networks (CNN) seem to be the approach utilized, while deep learning works as the model's theoretical foundation. The model is being built entirely from scratch. the shared-weights design and translation invariance features of CNN, sometimes referred to as Convent, a subclass of deep neural networks. Using the numerical technique of fourier is CNN. The linear computation subset covers convolution. Between both the layers of input and output a CNN is built up of numerous hidden layers. The network-based model now proceeds to process the input array of dimension 4 data. The number of filters was increased since achieving a flawless result with fewer mistakes was the primary objective. We originally started with 16 filters and left padding at its default setting to prevent data loss. Then, in order to reduce the breadth of our data, we employed the Max Pooling layer with pool size=2. After that, 128 filters were added in the following order: In order to categorise and delve further, dropout layers of 16, 32, 64, and 128 were utilised to lessen the chance of overfitting. The CNN layer is linked to the flattering layer via the flattering layer. The concealed layers are then connected using the "relu" triggering mechanism.

Food may be photographed at various depths to yield images of varied sizes. In a practical environment, we need a way to determine the amount of food or the number of calories. We need to know the real object sizes once the required food items have been recognised together with their masks because it is hard to do so from a pin-hole camera picture alone. Therefore, by comparing the food-objects to the size of the previously known object, we employ a referencing strategy to extract the true size of the food present in that particular image. In the same manner that the aforementioned experiment employed a coin as a reference object, we propose employing a plate as a standard object for the assessment of the food identified in photographs. Edge detection or training data may be utilised to recognise plates and edibles with a single network, respectively. After the plates have been discovered, the pixels per square inch are calculated using the actual size of the plate in real life. Once a meal's portion has been identified, its volume has been calculated while accounting for all of its different forms. In this instance, it was an apple. You may compute its first radius by multiplying it by pi (3.14). The sphere's volume is then calculated using the formula. 

![image](https://github.com/user-attachments/assets/4fbae738-215b-4bb1-8cc8-a0a8ad43f8cf)

The photos that cell phones took, collectively. For this collection of fruits, four categories have been created. Four fruit types and 2403 real-world photos are offered in this difficult data collection. The images were taken at various angles and from a range of fruit stores. Each of the diverse yet furthermore outwardly and semantically equivalent fruit classes has a total of 565 photos, of which 100 are training images and 465 are test images.

The testing is done using tickle software . The first step in testing is by taking the screenshot and extract its shape, color, size etc.. and converted as matrix. By using this it will conform whether it is feasible or not. After that the dataset which we give as a input will compare with the trained dataset. 

![image](https://github.com/user-attachments/assets/33b86a27-40f0-42b5-b20f-0daa3c546004)

![image](https://github.com/user-attachments/assets/d6256b8c-cecd-4b0e-b461-c0bca2d6b552)

![image](https://github.com/user-attachments/assets/ca6a8a66-7c65-42be-b097-cb0306a6c90c)

![image](https://github.com/user-attachments/assets/0ef3cb53-5083-498c-800d-d976aa259e98)

![image](https://github.com/user-attachments/assets/d326fb54-a54d-4c6e-8635-37c62c36472e)

![image](https://github.com/user-attachments/assets/f547d9dc-3afe-44b3-ba4d-147c7eb0a8ed)

![image](https://github.com/user-attachments/assets/48c92252-e918-4bf5-a217-12b12e08b832)
